{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from multiprocessing import Pool, Array, Process, Value, Manager\n",
    "import ctypes\n",
    "\n",
    "from six.moves import xrange\n",
    "import numpy as np\n",
    "from numpy.linalg import inv, cholesky\n",
    "from numpy.random import RandomState\n",
    "from scipy.stats import wishart\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.infer.mcmc import MCMC, NUTS\n",
    "\n",
    "# from exceptions import NotFittedError\n",
    "from sklearn.exceptions import NotFittedError\n",
    "# from utils.datasets import build_user_item_matrix\n",
    "# from utils.validation import check_ratings\n",
    "# from utils.evaluation import RMSE\n",
    "# from utils.datasets import load_movielens_1m_ratings\n",
    "# from utils.progress import printProgressBar\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pdb\n",
    "\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(0)\n",
    "\n",
    "rand_state = RandomState(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPMF():\n",
    "    def __init__(self, n_user, n_item, n_feature, beta=2.0, beta_user=2.0,\n",
    "                 df_user=None, mu0_user=0., beta_item=2.0, df_item=None,\n",
    "                 mu0_item=0., converge=1e-5, seed=None, max_rating=None,\n",
    "                 min_rating=None, output_file = None):\n",
    "\n",
    "        super(BPMF, self).__init__()\n",
    "\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.n_feature = n_feature\n",
    "        self.rand_state = RandomState(seed)\n",
    "        self.max_rating = float(max_rating) if max_rating is not None else None\n",
    "        self.min_rating = float(min_rating) if min_rating is not None else None\n",
    "        self.converge = converge\n",
    "        self.data = None\n",
    "        # Hyper Parameter\n",
    "        self.beta = beta\n",
    "\n",
    "        # Inv-Whishart (User features)\n",
    "        self.WI_user = np.eye(n_feature, dtype='float64')\n",
    "        self.beta_user = beta_user\n",
    "        self.df_user = int(df_user) if df_user is not None else n_feature\n",
    "        self.mu0_user = np.repeat(mu0_user, n_feature).reshape(n_feature, 1) \n",
    "        # Inv-Whishart (item features)\n",
    "        self.WI_item = np.eye(n_feature, dtype='float64')\n",
    "        self.beta_item = beta_item\n",
    "        self.df_item = int(df_item) if df_item is not None else n_feature\n",
    "        self.mu0_item = np.repeat(mu0_item, n_feature).reshape(n_feature, 1)\n",
    "\n",
    "        # Latent Variables\n",
    "        self.mu_user = np.zeros((n_feature, 1), dtype='float64')\n",
    "        self.mu_item = np.zeros((n_feature, 1), dtype='float64')\n",
    "\n",
    "        self.alpha_user = np.eye(n_feature, dtype='float64')\n",
    "        self.alpha_item = np.eye(n_feature, dtype='float64')\n",
    "\n",
    "        # initializes the user features randomly.\n",
    "        # (There is no special reason to use 0.3)\n",
    "        self.user_features_ = 0.3 * self.rand_state.rand(n_user, n_feature)\n",
    "        self.item_features_ = 0.3 * self.rand_state.rand(n_item, n_feature)\n",
    "\n",
    "        # average user/item features\n",
    "        self.avg_user_features_ = np.zeros((n_user, n_feature))\n",
    "        self.avg_item_features_ = np.zeros((n_item, n_feature))\n",
    "\n",
    "        # data state\n",
    "        self.iter_ = 0\n",
    "        self.mean_rating_ = None\n",
    "        self.ratings_csr_ = None\n",
    "        self.ratings_csc_ = None\n",
    "\n",
    "        check_ratings(ratings, self.n_user, self.n_item,\n",
    "                      self.max_rating, self.min_rating)\n",
    "\n",
    "        self.mean_rating_ = np.mean(ratings[:, 2])\n",
    "\n",
    "        # only two different ways of building the matrix.\n",
    "        # csr user-item matrix for fast row access (user update)\n",
    "        self.ratings_csr_ = build_user_item_matrix(\n",
    "            self.n_user, self.n_item, ratings)\n",
    "        # keep a csc matrix for fast col access (item update)\n",
    "        self.ratings_csc_ = self.ratings_csr_.tocsc()\n",
    "\n",
    "        self.output_file = output_file\n",
    "        self.n_thread = 20\n",
    "\n",
    "    def _update_item_params(self):\n",
    "        N = self.n_item\n",
    "        X_bar = np.mean(self.item_features_, 0).reshape((self.n_feature, 1))\n",
    "        # #print 'X_bar', X_bar.shape\n",
    "        S_bar = np.cov(self.item_features_.T)\n",
    "        # #print 'S_bar', S_bar.shape\n",
    "\n",
    "        diff_X_bar = self.mu0_item - X_bar\n",
    "\n",
    "        # W_{0}_star\n",
    "        WI_post = inv(inv(self.WI_item) +\n",
    "                      N * S_bar +\n",
    "                      np.dot(diff_X_bar, diff_X_bar.T) *\n",
    "                      (N * self.beta_item) / (self.beta_item + N))\n",
    "\n",
    "        # Note: WI_post and WI_post.T should be the same.\n",
    "        #       Just make sure it is symmertic here\n",
    "        WI_post = (WI_post + WI_post.T) / 2.0\n",
    "\n",
    "        # update alpha_item\n",
    "        df_post = self.df_item + N\n",
    "        self.alpha_item = wishart.rvs(df_post, WI_post, 1, self.rand_state)\n",
    "\n",
    "        # update mu_item\n",
    "        mu_mean = (self.beta_item * self.mu0_item + N * X_bar) / \\\n",
    "            (self.beta_item + N)\n",
    "\n",
    "        mu_var = inv(np.dot(self.beta_item + N, self.alpha_item))\n",
    "        return mu_mean, mu_var\n",
    "\n",
    "    def _update_user_params(self):\n",
    "        # same as _update_user_params\n",
    "        N = self.n_user\n",
    "        X_bar = np.mean(self.user_features_, 0).reshape((self.n_feature, 1))\n",
    "        S_bar = np.cov(self.user_features_.T)\n",
    "        # mu_{0} - U_bar\n",
    "        diff_X_bar = self.mu0_user - X_bar\n",
    "        # W_{0}_star \n",
    "        WI_post = inv(inv(self.WI_user) + \n",
    "                      N * S_bar + np.dot(diff_X_bar, diff_X_bar.T) * \n",
    "                      (N * self.beta_user) / (self.beta_user + N))\n",
    "        # Note: WI_post and WI_post.T should be the same.\n",
    "        #       Just make sure it is symmertic here\n",
    "        WI_post = (WI_post + WI_post.T) / 2.0\n",
    "        # update alpha_user\n",
    "        df_post = self.df_user + N\n",
    "        # LAMBDA_{U} ~ W(W{0}_star, df_post)\n",
    "        self.alpha_user = wishart.rvs(df_post, WI_post, 1, self.rand_state)\n",
    "        # update mu_user\n",
    "        # mu_{0}_star = (beta_{0} * mu_{0} + N * U_bar) / (beta_{0} + N) \n",
    "        mu_mean = (self.beta_user * self.mu0_user + N * X_bar) / (self.beta_user + N)\n",
    "        \n",
    "        #-------------------------------------------------------------------------\n",
    "        #mu_mean = [i[0] for i in mu_mean]\n",
    "        # decomposed inv(beta_{0}_star * LAMBDA_{U}) \n",
    "        #mu_var = cholesky(inv(np.dot(self.beta_user + N\n",
    "        #                , self.alpha_user)))[self.n_feature - 1]\n",
    "        mu_var = inv(np.dot(self.beta_user + N, self.alpha_user))\n",
    "        #---------------------------------------------------------------------------\n",
    "        return mu_mean, mu_var\n",
    "\n",
    "    def _update_item_features(self):\n",
    "        # Gibbs sampling for item features\n",
    "        #printProgressBar(0, self.n_item, prefix = 'Updating item features:', suffix = 'Complete', length = 40)\n",
    "        for item_id in xrange(self.n_item):\n",
    "            #printProgressBar(item_id, self.n_item, prefix = 'Updating item features:', suffix = 'Complete', length = 40)\n",
    "            indices = self.ratings_csc_[:, item_id].indices\n",
    "            features = self.user_features_[indices, :]\n",
    "            rating = self.ratings_csc_[:, item_id].data - self.mean_rating_\n",
    "            rating = np.reshape(rating, (rating.shape[0], 1))\n",
    "\n",
    "            covar = inv(self.alpha_item +\n",
    "                        self.beta * np.dot(features.T, features))\n",
    "            lam = cholesky(covar)\n",
    "\n",
    "            temp = (self.beta * np.dot(features.T, rating) +\n",
    "                    np.dot(self.alpha_item, self.mu_item))\n",
    "\n",
    "            mean = np.dot(covar, temp)\n",
    "            mean = Variable(torch.from_numpy(mean))\n",
    "            covar = Variable(torch.from_numpy(covar))\n",
    "            mean = torch.reshape(mean, (-1,))\n",
    "            temp_feature = pyro.sample('i_temp_feature' + str(item_id), dist.MultivariateNormal(mean, covariance_matrix=covar))  \n",
    "            self.item_features_[item_id, :] = temp_feature.detach().numpy().ravel()\n",
    "\n",
    "    def _update_user_features(self):\n",
    "        # Gibbs sampling for user features\n",
    "        for user_id in xrange(self.n_user):\n",
    "            indices = self.ratings_csr_[user_id, :].indices\n",
    "            features = self.item_features_[indices, :]\n",
    "            rating = self.ratings_csr_[user_id, :].data - self.mean_rating_\n",
    "            rating = np.reshape(rating, (rating.shape[0], 1))\n",
    "\n",
    "            covar = inv(self.alpha_user + self.beta * np.dot(features.T, features))\n",
    "            lam = cholesky(covar)\n",
    "            # aplha * sum(V_j * R_ij) + LAMBDA_U * mu_u\n",
    "            temp = (self.beta * np.dot(features.T, rating) +\n",
    "                    np.dot(self.alpha_user, self.mu_user))\n",
    "            # mu_i_star\n",
    "            mean = np.dot(covar, temp)\n",
    "            mean = Variable(torch.from_numpy(mean))\n",
    "            mean = torch.reshape(mean, (-1,))\n",
    "            covar = Variable(torch.from_numpy(covar))\n",
    "            temp_feature = pyro.sample('u_temp_feature' + str(user_id), dist.MultivariateNormal(mean, covariance_matrix=covar))\n",
    "            self.user_features_[user_id, :] = temp_feature.detach().numpy().ravel()\n",
    "\n",
    "    def _predict(self, data, is_train=False, avg_u_f=None, avg_i_f=None):\n",
    "        if not self.mean_rating_:\n",
    "            raise NotFittedError()\n",
    "\n",
    "        if not is_train:\n",
    "            u_features = self.user_features_.take(data.take(0, axis=1), axis=0)\n",
    "            i_features = self.item_features_.take(data.take(1, axis=1), axis=0)\n",
    "        else:\n",
    "            u_features = avg_u_f.take(data.take(0, axis=1), axis=0)\n",
    "            i_features = avg_i_f.take(data.take(1, axis=1), axis=0)\n",
    "\n",
    "        preds = np.sum(u_features * i_features, 1) + self.mean_rating_\n",
    "\n",
    "        if self.max_rating:\n",
    "            preds[preds > self.max_rating] = self.max_rating\n",
    "\n",
    "        if self.min_rating:\n",
    "            preds[preds < self.min_rating] = self.min_rating\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def _init_shared(self, _shared):\n",
    "        global shared_pred\n",
    "\n",
    "        shared_pred = np.frombuffer(_shared.get_obj()).reshape(-1)\n",
    "\n",
    "    def _sample(self, s, e, p, sigma, p2):\n",
    "        for i in range(s.value, e.value):\n",
    "            p2[i] = pyro.sample(\"obs\" + str(i), dist.Normal(p[i], sigma.value))\n",
    "\n",
    "    def _model(self, sigma):\n",
    "        self.iter_ += 1\n",
    "\n",
    "        i_mu_mean, i_mu_var = self._update_item_params()\n",
    "        u_mu_mean, u_mu_var = self._update_user_params()\n",
    "        for i in range(i_mu_var.shape[0]):\n",
    "            for j in range(i_mu_var.shape[1]):\n",
    "                if i_mu_var[i][j] <= 1e-6:\n",
    "                    i_mu_var[i][j] = 1e-6\n",
    "        for i in range(u_mu_var.shape[0]):\n",
    "            for j in range(u_mu_var.shape[1]):\n",
    "                if u_mu_var[i][j] <= 1e-6:\n",
    "                    u_mu_var[i][j] = 1e-6\n",
    "\n",
    "        i_mu_mean = Variable(torch.from_numpy(i_mu_mean))\n",
    "        i_mu_var = Variable(torch.from_numpy(i_mu_var))\n",
    "        u_mu_mean = Variable(torch.from_numpy(u_mu_mean))\n",
    "        u_mu_var = Variable(torch.from_numpy(u_mu_var))\n",
    "\n",
    "        i_mu_mean = torch.reshape(i_mu_mean, (-1,))\n",
    "        u_mu_mean = torch.reshape(u_mu_mean, (-1,))\n",
    "        while True:\n",
    "            try:\n",
    "                self.mu_item = pyro.sample('mu_item', dist.MultivariateNormal(i_mu_mean, covariance_matrix=i_mu_var))\n",
    "                break\n",
    "            except (RuntimeError, ValueError):\n",
    "                i_mu_var = 0.1 * torch.eye(self.n_feature, dtype=torch.float64)\n",
    "\n",
    "        self.mu_item = torch.reshape(self.mu_item, (self.n_feature,1)).detach().numpy()\n",
    "        while True:\n",
    "            try:\n",
    "                self.mu_user = pyro.sample('mu_user', dist.MultivariateNormal(u_mu_mean, covariance_matrix=u_mu_var))\n",
    "                break\n",
    "            except (RuntimeError, ValueError):\n",
    "                u_mu_var = 0.1 * torch.eye(self.n_feature,dtype=torch.float64)\n",
    "                \n",
    "        self.mu_user = torch.reshape(self.mu_user, (self.n_feature,1)).detach().numpy()\n",
    "        \n",
    "        self._update_item_features()\n",
    "        self._update_user_features()\n",
    "        \n",
    "        pred = self._predict(self.data)\n",
    "\n",
    "        pred_len = len(pred)\n",
    "        pred = Variable(torch.from_numpy(pred))\n",
    "\n",
    "        pred2 = pred\n",
    "        pred2_n = pred2.numpy()\n",
    "        \n",
    "        threads = self.n_thread\n",
    "        jobs = []\n",
    "        batch_size = pred_len // threads\n",
    "    \n",
    "        pred2 = Array('d', pred2_n)\n",
    "        sig = Value('d', sigma)\n",
    "        start = Value('i', 0)\n",
    "        end = Value('i', batch_size)\n",
    "        for i in range(threads):\n",
    "            if(i == (threads - 1)):\n",
    "                end = Value('i', pred_len)\n",
    "            p = Process(target=self._sample, args=[start, end, pred, sig, pred2])\n",
    "            jobs.append(p)\n",
    "            start = Value('i', start.value + batch_size)\n",
    "            end = Value('i', end.value + batch_size)\n",
    "\n",
    "        for j in jobs:\n",
    "            j.start()\n",
    "\n",
    "        for j in jobs:\n",
    "            j.join()\n",
    "        \n",
    "        pred2 = Variable(torch.from_numpy(np.array(pred2[:])))\n",
    "        return pred2\n",
    "    \n",
    "    def _conditioned_model(self,model, sigma, ratings):\n",
    "        data = dict()\n",
    "        \n",
    "        rating = ratings.take(2, axis=1)\n",
    "        rating_len = len(rating)\n",
    "            \n",
    "        for i in range(rating_len):\n",
    "            data[\"obs\" + str(i)] = torch.tensor(rating[i], dtype = torch.float64)\n",
    "        \n",
    "        return poutine.condition(model, data=data)(sigma)\n",
    " \n",
    "    #1000, 1000, 1 for defulat\n",
    "    def _main(self, ratings, sigma, args):\n",
    "        \n",
    "        self.n_thread = args.n_threads\n",
    "        # split data to training & testing\n",
    "        train_pct = 0.9\n",
    "\n",
    "        rand_state.shuffle(ratings)\n",
    "        train_size = int(train_pct * ratings.shape[0])\n",
    "        train = ratings[:train_size]\n",
    "        validation = ratings[train_size:]\n",
    "\n",
    "        self.data = train\n",
    "       \n",
    "        nuts_kernel = NUTS(self._conditioned_model, jit_compile=args.jit,)\n",
    "    \n",
    "        posterior = MCMC(nuts_kernel,\n",
    "                         num_samples=args.num_samples,\n",
    "                         warmup_steps=args.warmup_steps,\n",
    "                         num_chains=args.num_chains,\n",
    "                         disable_progbar=False).run(self._model, sigma, train)\n",
    "        \n",
    "        sites = ['mu_item', 'mu_user'] + ['u_temp_feature' + str(user_id) for user_id in xrange(self.n_user)] + ['i_temp_feature' + str(item_id) for item_id in xrange(self.n_item)]\n",
    "        marginal = posterior.marginal(sites=sites)\n",
    "        marginal = torch.cat(list(marginal.support(flatten=True).values()), dim=-1).cpu().numpy()\n",
    "        avg_mu_item = np.average(marginal[:, :self.n_feature], axis=0)\n",
    "        avg_mu_user = np.average(marginal[:, self.n_feature:2*self.n_feature], axis=0)\n",
    "        avg_u_temp_feature = np.average(marginal[:, 2*self.n_feature:2*self.n_feature + self.n_user*self.n_feature].reshape(-1,self.n_user,self.n_feature), axis=0)\n",
    "        avg_i_temp_feature = np.average(marginal[:, 2*self.n_feature + self.n_user*self.n_feature:].reshape(-1,self.n_item, self.n_feature), axis=0)\n",
    "        \n",
    "        train_preds = self._predict(train[:, :2], True, avg_u_temp_feature, avg_i_temp_feature)\n",
    "        train_rmse = RMSE(train_preds, train[:, 2])\n",
    "        val_preds = self._predict(validation[:, :2], True, avg_u_temp_feature, avg_i_temp_feature)\n",
    "        val_rmse = RMSE(val_preds, validation[:, 2])\n",
    "        print(\"After %d iteration, train RMSE: %.6f, validation RMSE: %.6f\" % (self.iter_, train_rmse, val_rmse))\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Bayesian Probabilistic Matrix Factorization')\n",
    "    parser.add_argument('--num-samples', type=int, default=8,\n",
    "                        help='number of MCMC samples (default: 8)')\n",
    "    parser.add_argument('--num-chains', type=int, default=1,\n",
    "                        help='number of parallel MCMC chains (default: 1)')\n",
    "    parser.add_argument('--warmup-steps', type=int, default=8,\n",
    "                        help='number of MCMC samples for warmup (default: 8)')\n",
    "    parser.add_argument('--jit', action='store_true', default=False)\n",
    "    parser.add_argument('--n_feature', type=int, default=30,\n",
    "                        help='number of feature dimension for each users and items (default: 30)')\n",
    "    parser.add_argument('--n_threads', type=int, default=20,\n",
    "                        help='number of threads (default: 20)')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    print(\"Loading data....\")\n",
    "    ratings = load_movielens_1m_ratings('../ml-1m/ratings-made.dat')\n",
    "    print(\"Loaded\")\n",
    "\n",
    "    output_file = open(\"mcmc_result.txt\", 'w')\n",
    "    n_user = max(ratings[:,0])\n",
    "    n_item = max(ratings[:,1])\n",
    "    ratings[:,(0,1)] -= 1\n",
    "    bpmf = BPMF(n_user=n_user, n_item=n_item, n_feature=args.n_feature,\n",
    "                max_rating=5., min_rating=1., seed= 0, output_file = output_file)\n",
    "    sigma = 0.5\n",
    "    bpmf._main(ratings, sigma, args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
